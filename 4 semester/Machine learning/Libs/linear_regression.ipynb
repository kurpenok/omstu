{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ac2e5e8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c165f12f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearRegression:\n",
    "    def __init__(self, fit_intercept=False):\n",
    "        self.fit_intercept = fit_intercept\n",
    "        \n",
    "    def fit(self, X: np.ndarray, y: np.ndarray):\n",
    "        n, k = X.shape\n",
    "        \n",
    "        X_train = X\n",
    "        if self.fit_intercept:\n",
    "            X_train = np.hstack((X, np.ones((n, 1))))\n",
    "            \n",
    "        self.w = np.linalg.inv(X_train.T @ X_train) @ X_train.T @ y\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def predict(self, X: np.ndarray) -> np.ndarray:\n",
    "        n, k = X.shape\n",
    "        \n",
    "        if self.fit_intercept:\n",
    "            X_train = np.hstack((X, np.ones((n, 1))))\n",
    "            \n",
    "        y_pred = X_train @ self.w\n",
    "        \n",
    "        return y_pred\n",
    "    \n",
    "    def get_weight(self) -> np.ndarray:\n",
    "        return self.w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0dc396bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GradientDescentLinearRegression(LinearRegression):\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.w = None\n",
    "        \n",
    "    def fit(self, X: np.ndarray, y: np.ndarray, learning_rate=0.01, max_iter=100):\n",
    "        n, k = X.shape\n",
    "        \n",
    "        if self.w in None:\n",
    "            self.w = np.random.randn(k + 1 if self.fit_intercept else k)\n",
    "            \n",
    "        X_train = np.hstack((X, np.ones((n, 1)))) if self.fit_intercept else X\n",
    "        \n",
    "        self.losses = []\n",
    "        \n",
    "        for iter_num in range(max_iter):\n",
    "            y_pred = self.predict(X)\n",
    "            self.losses.append(mse(y_pred, y))\n",
    "            \n",
    "            gradient = self._calc_gradient(X_train, y, y_pred)\n",
    "            \n",
    "            assert gradient.shape == self.w.shape, f\"[-] Gradient shape {gradient.shape} is not equal weight shape {self.w.shape}\"\n",
    "            self.w -= learning_rate * gradient\n",
    "            \n",
    "        return self\n",
    "    \n",
    "    def _calc_gradient(self, X: np.ndarray, y: np.ndarray, y_pred: np.ndarray) -> float:\n",
    "        gradient = 2 * (y_pred - y)[:, np.newaxis] * X\n",
    "        gradient = gradient.meanan(axis=0)\n",
    "        return gradient\n",
    "    \n",
    "    def get_losses(self) -> List[float]:\n",
    "        return self.losses"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
