\unnumsection{ПРИЛОЖЕНИЕ А}
\addcontentsline{toc}{section}{ПРИЛОЖЕНИЕ А}

\begin{minted}[frame=single, baselinestretch=1]{python}
#!/usr/bin/env python3

import os
import threading

import cv2
import numpy as np


class Capture:
    def __init__(self, grabbed: bool, frame: np.ndarray) -> None:
        self.grabbed: bool = grabbed
        self.frame: np.ndarray = frame.copy()


class StereoCamera:
    def __init__(
            self,
            sensor_id: int,
            frame_width: int,
            frame_height: int) -> None:
        
        self.sensor_id: int = sensor_id
        self.frame_width: int = frame_width
        self.frame_height: int = frame_height

        self.video_capture = cv2.VideoCapture(self.sensor_id)
        self.video_capture.set(cv2.CAP_PROP_FRAME_WIDTH, frame_width)
        self.video_capture.set(cv2.CAP_PROP_FRAME_HEIGHT, frame_height)

        grabbed, frame = self.video_capture.read()
        self.capture = Capture(grabbed, frame)

        self.read_thread: threading.Thread
        self.read_lock: threading.Lock = threading.Lock()

        self.running: bool = False

    def start(self) -> None:
        if self.running:
            print("[+] Video capturing already running!")
            return

        if self.video_capture:
            self.running = True
            self.read_thread = \
                threading.Thread(
                    target=self._update_camera,
                    daemon=True)
            self.read_thread.start()

    def stop(self) -> None:
        self.running = False
        self.read_thread.join()

    def _update_camera(self) -> None:
        while self.running:
            try:
                grabbed, frame = self.video_capture.read()
                with self.read_lock:
                    self.capture.grabbed = grabbed
                    self.capture.frame = frame
            except RuntimeError:
                print("[-] Could not read image from camera!")

    def read(self) -> Capture:
        with self.read_lock:
            grabbed = self.capture.grabbed
            frame = self.capture.frame.copy()
        return Capture(grabbed, frame)

    def release(self) -> None:
        if self.video_capture:
            self.video_capture.release()

        if self.read_thread:
            self.read_thread.join()


if __name__ == "__main__":
    os.environ["QT_LOGGING_RULES"] = "*.debug=false;qt.qpa.*=false"

    sensor_id = int(input("[>] Enter sensor ID: "))
    frame_width = 1280
    frame_height = 480

    camera = StereoCamera(sensor_id, frame_width, frame_height)
    camera.start()

    while True:
        capture = camera.read()
        grabbed = capture.grabbed
        frame = capture.frame

        if grabbed:
            cv2.imshow("[+] Camera image:", frame)

        if cv2.waitKey(1) == ord("q"):
            break

    camera.stop()
    camera.release()
    cv2.destroyAllWindows()
\end{minted}

\begin{minted}[frame=single, baselinestretch=1]{python}
#!/usr/bin/env python3

import os

import cv2
import numpy as np
from stereovision.calibration import StereoCalibration

from camera import StereoCamera

SWS = 29
PFS = 5
PFC = 20
MDS = 0
NOD = 80
TTH = 500
UR = 1
SR = 0
SPWS = 0


def load_map_settings():
    global SWS, PFS, PFC, MDS, NOD, TTH, UR, SR, SPWS, \
        loading_settings, sbm
    sbm = cv2.StereoBM().create(numDisparities=16, blockSize=SWS)
    sbm.setPreFilterType(1)
    sbm.setPreFilterSize(PFS)
    sbm.setPreFilterCap(PFC)
    sbm.setMinDisparity(MDS)
    sbm.setNumDisparities(NOD)
    sbm.setTextureThreshold(TTH)
    sbm.setUniquenessRatio(UR)
    sbm.setSpeckleRange(SR)
    sbm.setSpeckleWindowSize(SPWS)


def stereo_depth_map(rectified_pair):
    dmLeft = rectified_pair[0]
    dmRight = rectified_pair[1]
    disparity = sbm.compute(dmLeft, dmRight)
    disparity_normalized = cv2.normalize(
        disparity,
        disparity,
        0, 255, cv2.NORM_MINMAX)
    image = np.array(disparity_normalized, dtype=np.uint8)
    disparity_color = cv2.applyColorMap(image, cv2.COLORMAP_JET)
    return disparity_color, disparity_normalized


if __name__ == "__main__":
    os.environ["QT_LOGGING_RULES"] = "*.debug=false;qt.qpa.*=false"

    # sensor_id = int(input("[>] Enter sensor ID: "))
    # frame_width = int(input("[>] Enter frame width: "))
    # frame_height = int(input("[>] Enter frame height: "))

    sensor_id = 2
    frame_width = 1280
    frame_height = 480

    camera = StereoCamera(sensor_id, frame_width, frame_height)
    camera.start()
    load_map_settings()

    cv2.namedWindow("Depthmap")

    while True:
        capture = camera.read()
        grabbed = capture.grabbed
        frame = capture.frame

        if grabbed:
            left_frame = frame[:, : frame_width // 2]
            right_frame = frame[:, frame_width // 2 :]

            left_gray_frame = cv2.cvtColor(
                left_frame, cv2.COLOR_BGR2GRAY)
            right_gray_frame = cv2.cvtColor(
                right_frame, cv2.COLOR_BGR2GRAY)

            calibration_result_folder_path = "calibration_result"
            calibration = StereoCalibration(
                input_folder=calibration_result_folder_path)
            rectified_pair = calibration.rectify(
                (left_gray_frame, right_gray_frame))
            disparity_color, disparity_normalized = \
                stereo_depth_map(rectified_pair)

            output = cv2.addWeighted(
                left_frame, 0.5, disparity_color, 0.5, 0.0)
            cv2.imshow("DepthMap", np.hstack((disparity_color, output)))

            if cv2.waitKey(1) == ord("q"):
                break
            else:
                continue

    camera.stop()
    camera.release()
    cv2.destroyAllWindows()
\end{minted}
