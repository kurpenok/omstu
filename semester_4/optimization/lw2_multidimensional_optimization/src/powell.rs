use crate::golden_ratio::golden_ratio_search;

pub fn powell<F>(f: F, x_0: Vec<f64>, eps: f64, max_iter: usize) -> (Vec<f64>, f64)
where
    F: Fn(&Vec<f64>) -> f64,
{
    // Определяем размерность задачи (число переменных)
    let n = x_0.len();

    // Инициализируем вектор x начальными значениями
    let mut x = x_0;

    // Формируем первоначальный набор направлений – единичный базис
    let mut directions: Vec<Vec<f64>> = Vec::new();
    for i in 0..n {
        // Создаем вектор длины n, заполненный нулями
        let mut d = vec![0.0; n];

        // Устанавливаем 1 на позиции i, получая единичный вектор
        d[i] = 1.0;

        // Добавляем вектор направления в коллекцию
        directions.push(d);
    }

    // Главный цикл метода Пауэлла, который повторяется не более max_iter раз
    for _ in 0..max_iter {
        // Сохраняем начальное положение x для текущей итерации
        let x_start = x.clone();

        // Вычисляем значение функции в начальной точке
        let f_start = f(&x);

        // Инициализируем переменные для отслеживания наибольшего улучшения за итерацию
        let mut biggest_decrease = 0.0;
        let mut biggest_index = 0;
        let mut prev_f = f_start;

        // Производим последовательный поиск минимума вдоль каждого из текущих направлений
        for i in 0..n {
            // Получаем i-й вектор направления
            let d = &directions[i];

            // Определяем одномерную функцию оптимизации вдоль направления d:
            // f1d(alpha) = f(x + alpha * d)
            let f1d = |alpha: f64| {
                // Клонируем текущую точку x
                let mut x_new = x.clone();

                for j in 0..n {
                    // Для каждой координаты вычисляем новое значение сдвига: x_new[j] = x[j] + alpha * d[j]
                    x_new[j] += alpha * d[j];
                }

                // Возвращаем значение функции в новой точке.
                f(&x_new)
            };

            // Выполняем одномерный поиск минимума вдоль направления d в интервале [-1, 1]
            // с заданной точностью eps
            let (alpha_min, _) = golden_ratio_search(f1d, -1.0, 1.0, eps);

            // Обновляем точку x, перемещаясь на расстояние alpha_min вдоль направления d
            for j in 0..n {
                x[j] += alpha_min * d[j];
            }

            // Вычисляем значение функции в новой точке
            let f_new = f(&x);

            // Определяем улучшение (снижение функции) по сравнению с предыдущим значением
            let decrease = prev_f - f_new;

            // Если это улучшение больше, чем фиксированное ранее, запоминаем соответствующий индекс направления
            if decrease > biggest_decrease {
                biggest_decrease = decrease;
                biggest_index = i;
            }

            // Обновляем предыдущее значение функции для следующего шага
            prev_f = f_new;
        }

        // Вычисляем суммарный сдвиг (разницу) вектора x относительно начала итерации x_start
        let mut diff = vec![0.0; n];
        for i in 0..n {
            diff[i] = x[i] - x_start[i];
        }

        // Определяем функцию оптимизации вдоль нового направления diff:
        // f1d(alpha) = f(x_start + alpha * diff)
        let f1d = |alpha: f64| {
            let mut x_new = x_start.clone();
            for i in 0..n {
                x_new[i] += alpha * diff[i];
            }
            f(&x_new)
        };

        // Проводим одномерный поиск минимума вдоль направления diff в интервале [-1, 1]
        let (alpha_min, _) = golden_ratio_search(f1d, -1.0, 1.0, eps);

        // Вычисляем кандидат на новое положение: x_new2 = x_start + alpha_min * diff
        let mut x_new2 = x_start.clone();
        for i in 0..n {
            x_new2[i] += alpha_min * diff[i];
        }

        // Если кандидат улучшает значение функции, обновляем текущую точку x
        if f(&x_new2) < f(&x) {
            x = x_new2;
        }

        // Обновляем набор направлений: заменяем направление с наибольшим улучшением новым направлением diff
        directions[biggest_index] = diff;

        // Вычисляем норму разности между новым и начальным положением за итерацию
        let norm: f64 = x
            .iter()
            .zip(x_start.iter())
            .map(|(xi, x0i)| (xi - x0i).powi(2))
            .sum::<f64>()
            .sqrt();

        // Если изменение меньше заданного порога eps, считаем, что достигнута сходимость и прерываем цикл
        if norm < eps {
            break;
        }
    }

    // Возвращаем найденное приближение минимума функции
    (x.clone(), f(&x))
}
